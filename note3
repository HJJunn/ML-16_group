1. 정규 방정식에서 세타 값의 의미는 입력 변수 행렬과 목표 변수 벡터를 연산해 손실함수 값을 0에 가깝게 하는 값을 말한다.

2. 선형회귀 코드에서 X 값은 2*(1이하 난수 행렬), Y 값은 난수행렬과의 합으로 x,y 축 라벨링 후 axis 함수를 통해 제한 범위를 설정했다.
   그 후, 각 값을 배치해 그래프로 나타내었다.
3. Learning Schedule?
  확률적 경사하강법은 무작의 샘플에 gradients를 구하기 때문에
  진폭이 크고 불안정하게 움직인다.
  손실 함수가 최솟값으로 과는 과정이 불안하다보니 전역 최솟값을 찾는데 어려움을 겪을 수 있다.
  Learning Schedule은 learning rate를 크게 설정하고 점차 작게 줄여서 지역 최솟값에 빠지지 않도록 조절하는 과정을 말한다.

4. 확률적 경사 하강법 코드 짜기
for i in range(m) : 1개의 샘플로 m번 반복epoch)
무작위로 뽑은 샘플 random_index 변수로 저장
learning_rate = learning_schedule(epoch * m + i)
그 다음은 배치경사 하강법과 동일
5.Quiz
총 1000개의 데이터 셋에서 총 50개의 미니 배치가 있는 경우 배치 사이즈는 20, SGD는 50를 50회 반복한다.
즉, iteration 50회당 1 epoch가 된다. 만약 epoch를 10회 반복한다면 가중치 갱신은 10 X 50 = 500회가 일어난다.

